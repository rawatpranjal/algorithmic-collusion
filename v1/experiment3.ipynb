{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating experiments:   9%|â–‰         | 46/500 [25:56<3:16:55, 26.03s/it]"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "\n",
    "DEBUG = False\n",
    "def dprint(*args):\n",
    "    if DEBUG:\n",
    "        print(*args)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 1) Valuation with eta (normalized)\n",
    "# --------------------------------------------------------------\n",
    "def get_valuation(eta, own_signal, others_signals):\n",
    "    alpha = 1.0 - 0.5 * eta\n",
    "    beta = 0.5 * eta\n",
    "    return alpha * own_signal + beta * np.mean(others_signals)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 2) Payoffs\n",
    "# --------------------------------------------------------------\n",
    "def get_payoffs(bids, valuations, auction_type):\n",
    "    n_bidders = len(bids)\n",
    "    rewards = np.zeros(n_bidders)\n",
    "    sorted_indices = np.argsort(bids)[::-1]\n",
    "    winner = sorted_indices[0]\n",
    "    highest_bid = bids[winner]\n",
    "\n",
    "    # Tie-breaking\n",
    "    tied_indices = [i for i in sorted_indices if bids[i] == highest_bid]\n",
    "    if len(tied_indices) > 1:\n",
    "        winner = random.choice(tied_indices)\n",
    "\n",
    "    second_highest_bid = bids[sorted_indices[1]] if len(bids) > 1 else highest_bid\n",
    "\n",
    "    if auction_type == \"first\":\n",
    "        rewards[winner] = valuations[winner] - highest_bid\n",
    "    else:\n",
    "        rewards[winner] = valuations[winner] - second_highest_bid\n",
    "\n",
    "    return rewards, winner, highest_bid\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 3) Bandit helpers: UCB and Linear (Contextual)\n",
    "# --------------------------------------------------------------\n",
    "class UCBBandit:\n",
    "    def __init__(self, n_actions, c):\n",
    "        self.n_actions = n_actions\n",
    "        self.c = c\n",
    "        self.counts = np.zeros(n_actions)\n",
    "        self.sums = np.zeros(n_actions)\n",
    "        self.total_pulls = 0\n",
    "\n",
    "    def select_action(self):\n",
    "        # If any action not tried, pick it\n",
    "        untried = np.where(self.counts == 0)[0]\n",
    "        if len(untried) > 0:\n",
    "            return np.random.choice(untried)\n",
    "        # Otherwise pick UCB\n",
    "        avg = self.sums / self.counts\n",
    "        ucb = avg + self.c * np.sqrt(np.log(self.total_pulls) / self.counts)\n",
    "        return np.argmax(ucb)\n",
    "\n",
    "    def update(self, action, reward):\n",
    "        self.counts[action] += 1\n",
    "        self.sums[action] += reward\n",
    "        self.total_pulls += 1\n",
    "\n",
    "class LinearContextualBandit:\n",
    "    def __init__(self, n_actions, context_dim, c, reg=1.0):\n",
    "        self.n_actions = n_actions\n",
    "        self.context_dim = context_dim\n",
    "        self.c = c\n",
    "        self.reg = reg\n",
    "        # For each action, maintain A (X'X + regI) and b (X'y)\n",
    "        self.A = [reg * np.eye(context_dim) for _ in range(n_actions)]\n",
    "        self.b = [np.zeros((context_dim,)) for _ in range(n_actions)]\n",
    "\n",
    "    def select_action(self, context):\n",
    "        # For each action, estimate reward = theta' * x + bonus\n",
    "        # theta = A_inv * b\n",
    "        mu = []\n",
    "        for a in range(self.n_actions):\n",
    "            A_inv = np.linalg.inv(self.A[a])\n",
    "            theta_hat = A_inv @ self.b[a]\n",
    "            mean_est = theta_hat @ context\n",
    "            var_est = context.T @ A_inv @ context\n",
    "            bonus = self.c * np.sqrt(var_est)\n",
    "            mu.append(mean_est + bonus)\n",
    "        return np.argmax(mu)\n",
    "\n",
    "    def update(self, action, context, reward):\n",
    "        # A[a] += x*x', b[a] += x*r\n",
    "        self.A[action] += np.outer(context, context)\n",
    "        self.b[action] += context * reward\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 4) Run bandit experiment (replaces Q-learning)\n",
    "# --------------------------------------------------------------\n",
    "def run_bandit_experiment(\n",
    "    eta, auction_type, bandit_type, c, n_bidders,\n",
    "    n_val_bins=6, n_bid_bins=6, seed=0, max_rounds=200_000,\n",
    "    conv_window=1000, conv_thresh=1e-3\n",
    "):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Discretized bid actions\n",
    "    actions = np.linspace(0, 1, n_bid_bins)\n",
    "\n",
    "    # Initialize bandits\n",
    "    if bandit_type == \"ucb\":\n",
    "        bandits = [UCBBandit(n_bid_bins, c) for _ in range(n_bidders)]\n",
    "    else:  # 'contextual'\n",
    "        # context_dim = 3 (own_signal, last_median_bid, last_winning_bid)\n",
    "        bandits = [LinearContextualBandit(n_bid_bins, 3, c) for _ in range(n_bidders)]\n",
    "\n",
    "    revenues = []\n",
    "    past_bids = np.zeros(n_bidders)\n",
    "    past_winner_bid = 0.0\n",
    "\n",
    "    def get_context(bidder_signal, median_bid, winner_bid):\n",
    "        return np.array([bidder_signal, median_bid, winner_bid])\n",
    "\n",
    "    time_to_converge = max_rounds\n",
    "    for r in range(max_rounds):\n",
    "        # Signals in [0, 1]\n",
    "        signals = np.random.randint(n_val_bins, size=n_bidders) / (n_val_bins - 1)\n",
    "\n",
    "        # Valuations\n",
    "        valuations = [get_valuation(eta, signals[i], np.delete(signals, i)) \n",
    "                      for i in range(n_bidders)]\n",
    "\n",
    "        # Each bidder picks bid\n",
    "        chosen_bids = []\n",
    "        for i in range(n_bidders):\n",
    "            context = get_context(signals[i], np.median(np.delete(past_bids, i)), past_winner_bid)\n",
    "            if bandit_type == \"ucb\":\n",
    "                a = bandits[i].select_action()\n",
    "            else:\n",
    "                a = bandits[i].select_action(context)\n",
    "            chosen_bids.append((i, a, context))\n",
    "\n",
    "        bids = [actions[a[1]] for a in chosen_bids]\n",
    "        rewards, winner, highest_bid = get_payoffs(bids, valuations, auction_type)\n",
    "\n",
    "        # Update bandits\n",
    "        for (i, a, context) in chosen_bids:\n",
    "            bandit_reward = rewards[i]\n",
    "            if bandit_type == \"ucb\":\n",
    "                bandits[i].update(a, bandit_reward)\n",
    "            else:\n",
    "                bandits[i].update(a, context, bandit_reward)\n",
    "\n",
    "        # Track revenue (max bid)\n",
    "        revenues.append(np.max(bids))\n",
    "        # Update memory\n",
    "        past_bids = np.array(bids)\n",
    "        past_winner_bid = highest_bid\n",
    "\n",
    "        # Convergence check\n",
    "        if r >= conv_window:\n",
    "            recent = revenues[-conv_window:]\n",
    "            if np.std(recent) < conv_thresh:\n",
    "                time_to_converge = r\n",
    "                break\n",
    "\n",
    "    avg_rev = np.mean(revenues[-conv_window:])\n",
    "    return avg_rev, time_to_converge, np.mean(1.0 - np.array(revenues))\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 5) Main experiment loop\n",
    "# --------------------------------------------------------------\n",
    "def main_experiment(K=50):\n",
    "    results = []\n",
    "    auction_type_options = [\"first\", \"second\"]\n",
    "    bandit_type_options = [\"ucb\", \"contextual\"]\n",
    "\n",
    "    for seed in trange(K, desc=\"Generating experiments\"):\n",
    "        eta = random.uniform(0.0, 1.0)\n",
    "        c = random.uniform(0.01, 2.0)  # exploration parameter\n",
    "        n_bidders = random.choice([2, 4, 6])\n",
    "        bandit_type = random.choice(bandit_type_options)\n",
    "        auction_type = random.choice(auction_type_options)\n",
    "\n",
    "        avg_rev, time_to_converge, avg_regret = run_bandit_experiment(\n",
    "            eta=eta,\n",
    "            auction_type=auction_type,\n",
    "            bandit_type=bandit_type,\n",
    "            c=c,\n",
    "            n_bidders=n_bidders,\n",
    "            seed=seed\n",
    "        )\n",
    "\n",
    "        results.append({\n",
    "            \"eta\": eta,\n",
    "            \"c\": c,\n",
    "            \"auction_type\": auction_type,\n",
    "            \"bandit_type\": bandit_type,\n",
    "            \"n_bidders\": n_bidders,\n",
    "            \"avg_rev\": avg_rev,\n",
    "            \"time_to_converge\": time_to_converge,\n",
    "            \"avg_regret_seller\": avg_regret\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 6) Run and save data\n",
    "# --------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    os.makedirs(\"experiment3\", exist_ok=True)\n",
    "    df = main_experiment(K=500)\n",
    "    csv_path = \"experiment3/data.csv\"\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"Data generation complete. Saved to '{csv_path}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Variable Definitions ===\n",
      "|    | Parameter         | Definition                                         |\n",
      "|----|-------------------|----------------------------------------------------|\n",
      "|  0 | eta               | Affiliation parameter (0.0 to 1.0).                |\n",
      "|  1 | c                 | Exploration parameter in UCB/Contextual bandits.   |\n",
      "|  2 | auction_type      | Treatment: 0 = first-price, 1 = second-price.      |\n",
      "|  3 | bandit_type       | 0 = linear contextual, 1 = UCB.                    |\n",
      "|  4 | n_bidders         | Number of bidders (2, 4, or 6).                    |\n",
      "|  5 | avg_rev           | Average seller revenue (last ~convergence window). |\n",
      "|  6 | time_to_converge  | Round index at which revenue stabilized.           |\n",
      "|  7 | avg_regret_seller | Average regret for the seller (1 - revenue).       |\n",
      "\n",
      "=== Summary Statistics ===\n",
      "|                   |          mean |          std |          min |          25% |           50% |           75% |           max |\n",
      "|-------------------|---------------|--------------|--------------|--------------|---------------|---------------|---------------|\n",
      "| eta               |      0.493367 |     0.304772 |    0.0115656 |     0.23023  |      0.50361  |      0.755831 |      0.985975 |\n",
      "| c                 |      0.893454 |     0.612604 |    0.0111641 |     0.328801 |      0.87983  |      1.32537  |      1.95741  |\n",
      "| n_bidders         |      3.6      |     1.52225  |    2         |     2        |      4        |      4        |      6        |\n",
      "| bandit_type       |      0.433333 |     0.504007 |    0         |     0        |      0        |      1        |      1        |\n",
      "| auction_type      |      0.366667 |     0.490133 |    0         |     0        |      0        |      1        |      1        |\n",
      "| avg_rev           |      0.484287 |     0.212647 |    0         |     0.3637   |      0.4944   |      0.6      |      0.8466   |\n",
      "| time_to_converge  | 127478        | 86693.2      | 1046         | 38066.2      | 200000        | 200000        | 200000        |\n",
      "| avg_regret_seller |      0.48229  |     0.187266 |    0.155715  |     0.369041 |      0.474049 |      0.590537 |      0.783385 |\n",
      "\n",
      "=== Correlations with auction_type ===\n",
      "| Variable          |   Correlation |     p-value |\n",
      "|-------------------|---------------|-------------|\n",
      "| eta               |     0.0651524 | 0.73231     |\n",
      "| c                 |     0.0574368 | 0.763052    |\n",
      "| n_bidders         |    -0.0739474 | 0.697758    |\n",
      "| bandit_type       |    -0.107018  | 0.573518    |\n",
      "| avg_rev           |     0.634119  | 0.0001681   |\n",
      "| time_to_converge  |     0.0653174 | 0.731656    |\n",
      "| avg_regret_seller |    -0.797709  | 1.30149e-07 |\n",
      "\n",
      "========== AVG_REV | ATE Results ==========\n",
      "                  coef   std err         t     P>|t|    2.5 %    97.5 %\n",
      "auction_type  0.276754  0.065095  4.251542  0.000021  0.14917  0.404337\n",
      "\n",
      "T-tests for GATE (avg_rev):\n",
      "| Variable    |   Group0_Effect |   Group1_Effect |   Diff(Group1-Group0) |   StdErr(Diff) |   t-value |   p-value |\n",
      "|-------------|-----------------|-----------------|-----------------------|----------------|-----------|-----------|\n",
      "| bandit_type |          0.2856 |          0.2651 |               -0.0205 |         0.1359 |   -0.1509 |    0.8801 |\n",
      "\n",
      "========== TIME_TO_CONVERGE | ATE Results ==========\n",
      "                      coef       std err         t     P>|t|         2.5 %  \\\n",
      "auction_type  13953.937319  33838.678727  0.412366  0.680071 -52368.654271   \n",
      "\n",
      "                    97.5 %  \n",
      "auction_type  80276.528909  \n",
      "\n",
      "T-tests for GATE (time_to_converge):\n",
      "| Variable    |   Group0_Effect |   Group1_Effect |   Diff(Group1-Group0) |   StdErr(Diff) |   t-value |   p-value |\n",
      "|-------------|-----------------|-----------------|-----------------------|----------------|-----------|-----------|\n",
      "| bandit_type |           21272 |         4384.11 |              -16887.9 |        70611.8 |   -0.2392 |     0.811 |\n",
      "\n",
      "========== AVG_REGRET_SELLER | ATE Results ==========\n",
      "                  coef   std err         t         P>|t|     2.5 %  97.5 %\n",
      "auction_type -0.309167  0.041769 -7.401758  1.343930e-13 -0.391033 -0.2273\n",
      "\n",
      "T-tests for GATE (avg_regret_seller):\n",
      "| Variable    |   Group0_Effect |   Group1_Effect |   Diff(Group1-Group0) |   StdErr(Diff) |   t-value |   p-value |\n",
      "|-------------|-----------------|-----------------|-----------------------|----------------|-----------|-----------|\n",
      "| bandit_type |         -0.2953 |         -0.3273 |               -0.0321 |          0.087 |   -0.3684 |    0.7126 |\n",
      "\n",
      "All analysis complete. Results saved in 'experiment3/' directory.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import doubleml\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import doubleml as dml\n",
    "from doubleml import DoubleMLData, DoubleMLIRM\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "import patsy\n",
    "from scipy.stats import norm, pearsonr\n",
    "from tabulate import tabulate\n",
    "import math\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ------------------------------------------------------------------------------\n",
    "    # 1) Variable definitions and reading data\n",
    "    # ------------------------------------------------------------------------------\n",
    "    var_definitions = {\n",
    "        \"eta\": \"Affiliation parameter (0.0 to 1.0).\",\n",
    "        \"c\": \"Exploration parameter in UCB/Contextual bandits.\",\n",
    "        \"auction_type\": \"Treatment: 0 = first-price, 1 = second-price.\",\n",
    "        \"bandit_type\": \"0 = linear contextual, 1 = UCB.\",\n",
    "        \"n_bidders\": \"Number of bidders (2, 4, or 6).\",\n",
    "        \"avg_rev\": \"Average seller revenue (last ~convergence window).\",\n",
    "        \"time_to_converge\": \"Round index at which revenue stabilized.\",\n",
    "        \"avg_regret_seller\": \"Average regret for the seller (1 - revenue).\"\n",
    "    }\n",
    "\n",
    "    df_var_defs = pd.DataFrame(\n",
    "        [{\"Parameter\": k, \"Definition\": v} for k, v in var_definitions.items()]\n",
    "    )\n",
    "    print(\"\\n=== Variable Definitions ===\")\n",
    "    print(tabulate(df_var_defs, headers=\"keys\", tablefmt=\"github\"))\n",
    "\n",
    "    # Load data from experiment3\n",
    "    df = pd.read_csv(\"experiment3/data.csv\")\n",
    "\n",
    "    # Recode auction_type: 'second' -> 1, 'first' -> 0 if needed\n",
    "    # Note: If the data was stored as strings, we'd do something like:\n",
    "    # df[\"auction_type\"] = (df[\"auction_type\"] == \"second\").astype(int)\n",
    "    # But if it's already 0/1, skip. Make sure to unify to 0=first, 1=second.\n",
    "    df[\"auction_type\"] = (df[\"auction_type\"] == \"second\").astype(int)\n",
    "\n",
    "    # Convert time_to_converge to fraction of total rounds if desired\n",
    "    # (In this experiment, it might be an absolute round index, no denominator.)\n",
    "    # Example if max_rounds is known, we can do:\n",
    "    # df[\"time_to_converge\"] /= 200000\n",
    "\n",
    "    # ------------------------------------------------------------------------------\n",
    "    # 2) Set up columns\n",
    "    # ------------------------------------------------------------------------------\n",
    "    treatment_col = \"auction_type\"\n",
    "    # We'll treat bandit_type as binary: 0=linear, 1=ucb\n",
    "    # So let's recode it similarly:\n",
    "    df[\"bandit_type\"] = (df[\"bandit_type\"] == \"ucb\").astype(int)\n",
    "\n",
    "    covariates_list = [\"eta\", \"c\", \"n_bidders\", \"bandit_type\"]\n",
    "    outcomes_list = [\"avg_rev\", \"time_to_converge\", \"avg_regret_seller\"]\n",
    "\n",
    "    # Ensure numeric columns are numeric\n",
    "    # (In case they've come in as strings, factor them):\n",
    "    for col in [treatment_col] + covariates_list + outcomes_list:\n",
    "        if df[col].dtype not in [np.float64, np.int64, float, int]:\n",
    "            df[col], _ = pd.factorize(df[col])\n",
    "\n",
    "    # ------------------------------------------------------------------------------\n",
    "    # 3) Summary statistics\n",
    "    # ------------------------------------------------------------------------------\n",
    "    cols_for_summary = covariates_list + [treatment_col] + outcomes_list\n",
    "    summary_stats = df[cols_for_summary].describe().T.drop(\"count\", axis=1, errors=\"ignore\")\n",
    "    print(\"\\n=== Summary Statistics ===\")\n",
    "    print(tabulate(summary_stats, headers=\"keys\", tablefmt=\"github\"))\n",
    "\n",
    "    # ------------------------------------------------------------------------------\n",
    "    # 4) Correlations with treatment\n",
    "    # ------------------------------------------------------------------------------\n",
    "    corr_results = []\n",
    "    for col in cols_for_summary:\n",
    "        if col != treatment_col:\n",
    "            r, p = pearsonr(df[col], df[treatment_col])\n",
    "            corr_results.append({\"Variable\": col, \"Correlation\": r, \"p-value\": p})\n",
    "\n",
    "    print(\"\\n=== Correlations with auction_type ===\")\n",
    "    print(tabulate(corr_results, headers=\"keys\", tablefmt=\"github\"))\n",
    "\n",
    "    # ------------------------------------------------------------------------------\n",
    "    # 5) DoubleML Analysis: ATE, GATE, CATE\n",
    "    # ------------------------------------------------------------------------------\n",
    "    # Create an output folder\n",
    "    out_dir = \"experiment3\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    for outcome in outcomes_list:\n",
    "        # Prepare for DoubleML\n",
    "        df[\"Y\"] = df[outcome]\n",
    "        dml_data = doubleml.DoubleMLData(\n",
    "            df, y_col=\"Y\", d_cols=treatment_col, x_cols=covariates_list\n",
    "        )\n",
    "\n",
    "        ml_g = LGBMRegressor(random_state=123, verbose=-1)\n",
    "        ml_m = LGBMClassifier(random_state=123, verbose=-1)\n",
    "\n",
    "        dml_irm = doubleml.DoubleMLIRM(\n",
    "            dml_data, ml_g=ml_g, ml_m=ml_m,\n",
    "            n_folds=10, n_rep=1, score=\"ATE\"\n",
    "        )\n",
    "        dml_irm.fit()\n",
    "\n",
    "        print(f\"\\n========== {outcome.upper()} | ATE Results ==========\")\n",
    "        print(dml_irm.summary)\n",
    "\n",
    "        # --------------------------------------\n",
    "        # GATE for binary covariates\n",
    "        # --------------------------------------\n",
    "        binary_covs = [c for c in covariates_list if df[c].nunique() == 2]\n",
    "        n_bin = len(binary_covs)\n",
    "        if n_bin > 0:\n",
    "            nrows_gate = math.ceil(n_bin / 3)\n",
    "            ncols_gate = min(n_bin, 3)\n",
    "            fig_gate, axes_gate = plt.subplots(\n",
    "                nrows=nrows_gate, ncols=ncols_gate,\n",
    "                figsize=(5 * ncols_gate, 4 * nrows_gate)\n",
    "            )\n",
    "            if n_bin == 1:\n",
    "                axes_gate = np.array([axes_gate])\n",
    "            gate_results = []\n",
    "\n",
    "            for i, bin_col in enumerate(binary_covs):\n",
    "                groups_df = df[[bin_col]].astype(\"category\")\n",
    "                gate_obj = dml_irm.gate(groups=groups_df)\n",
    "                ci_95 = gate_obj.confint(level=0.95)\n",
    "                eff = ci_95[\"effect\"]\n",
    "                lo = ci_95[\"2.5 %\"]\n",
    "                hi = ci_95[\"97.5 %\"]\n",
    "                gate_sum = gate_obj.summary\n",
    "                errs = gate_sum[\"std err\"]\n",
    "\n",
    "                ax = axes_gate.flatten()[i] if n_bin > 1 else axes_gate[0]\n",
    "                x_pos = np.arange(len(eff))\n",
    "                ax.errorbar(x_pos, eff, yerr=[eff - lo, hi - eff], fmt=\"o\", capsize=5)\n",
    "                ax.set_title(f\"GATE: {bin_col} ({outcome})\")\n",
    "                ax.set_xticks(x_pos)\n",
    "                ax.set_xticklabels([f\"{bin_col}={lvl}\" for lvl in range(len(eff))])\n",
    "                ax.set_ylabel(\"Estimated GATE\")\n",
    "\n",
    "                # For two-group difference (if any)\n",
    "                if len(eff) == 2:\n",
    "                    dval = eff.iloc[1] - eff.iloc[0]\n",
    "                    dvar = errs.iloc[1]**2 + errs.iloc[0]**2\n",
    "                    dse = math.sqrt(dvar)\n",
    "                    tval = dval / dse\n",
    "                    pval = 2.0 * (1.0 - norm.cdf(abs(tval)))\n",
    "                    gate_results.append({\n",
    "                        \"Variable\": bin_col,\n",
    "                        \"Group0_Effect\": f\"{eff.iloc[0]:.4f}\",\n",
    "                        \"Group1_Effect\": f\"{eff.iloc[1]:.4f}\",\n",
    "                        \"Diff(Group1-Group0)\": f\"{dval:.4f}\",\n",
    "                        \"StdErr(Diff)\": f\"{dse:.4f}\",\n",
    "                        \"t-value\": f\"{tval:.4f}\",\n",
    "                        \"p-value\": f\"{pval:.4f}\"\n",
    "                    })\n",
    "\n",
    "            fig_gate.tight_layout()\n",
    "            gate_path = os.path.join(out_dir, f\"gate_plots_{outcome}.png\")\n",
    "            fig_gate.savefig(gate_path, bbox_inches=\"tight\")\n",
    "            plt.close(fig_gate)\n",
    "\n",
    "            if gate_results:\n",
    "                print(f\"\\nT-tests for GATE ({outcome}):\")\n",
    "                print(tabulate(gate_results, headers=\"keys\", tablefmt=\"github\"))\n",
    "\n",
    "        # --------------------------------------\n",
    "        # CATE for continuous covariates\n",
    "        # --------------------------------------\n",
    "        cont_covs = [c for c in covariates_list if df[c].nunique() > 2]\n",
    "        n_cont = len(cont_covs)\n",
    "        if n_cont > 0:\n",
    "            nrows_cate = math.ceil(n_cont / 3)\n",
    "            ncols_cate = min(n_cont, 3)\n",
    "            fig_cate, axes_cate = plt.subplots(\n",
    "                nrows=nrows_cate, ncols=ncols_cate,\n",
    "                figsize=(5 * ncols_cate, 4 * nrows_cate)\n",
    "            )\n",
    "            if n_cont == 1:\n",
    "                axes_cate = np.array([axes_cate])\n",
    "\n",
    "            for i, cont_col in enumerate(cont_covs):\n",
    "                # Using spline expansions\n",
    "                design_matrix = patsy.dmatrix(f\"bs({cont_col}, df=5, degree=2)\", df)\n",
    "                spline_basis = pd.DataFrame(design_matrix)\n",
    "                cate_obj = dml_irm.cate(basis=spline_basis)\n",
    "                ci_95_cate = cate_obj.confint(basis=spline_basis, level=0.95)\n",
    "                eff_cate = ci_95_cate[\"effect\"].values\n",
    "                lo_cate = ci_95_cate[\"2.5 %\"].values\n",
    "                hi_cate = ci_95_cate[\"97.5 %\"].values\n",
    "\n",
    "                xvals = df[cont_col].values\n",
    "                idx_sort = np.argsort(xvals)\n",
    "                x_sort = xvals[idx_sort]\n",
    "                eff_sort = eff_cate[idx_sort]\n",
    "                lo_sort = lo_cate[idx_sort]\n",
    "                hi_sort = hi_cate[idx_sort]\n",
    "\n",
    "                axc = axes_cate.flatten()[i] if n_cont > 1 else axes_cate[0]\n",
    "                axc.plot(x_sort, eff_sort, label=\"CATE\")\n",
    "                axc.fill_between(x_sort, lo_sort, hi_sort, alpha=0.2, label=\"95% CI\")\n",
    "                axc.set_title(f\"CATE: {cont_col} ({outcome})\")\n",
    "                axc.set_xlabel(cont_col)\n",
    "                axc.set_ylabel(\"Estimated TE\")\n",
    "                axc.legend()\n",
    "\n",
    "            fig_cate.tight_layout()\n",
    "            cate_path = os.path.join(out_dir, f\"cate_plots_{outcome}.png\")\n",
    "            fig_cate.savefig(cate_path, bbox_inches=\"tight\")\n",
    "            plt.close(fig_cate)\n",
    "\n",
    "    print(\"\\nAll analysis complete. Results saved in 'experiment3/' directory.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
