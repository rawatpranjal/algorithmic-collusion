\section{Conclusion}

A consistent finding across all three experiments is that first-price auctions systematically yield lower revenue and higher seller regret than their second-price counterparts. This pattern persists regardless of whether bidders have constant valuations, affiliated valuations, or whether the learning agents are Q-learners or LinUCB bandits. The recurring shortfall in revenue underscores how first-price mechanisms can incentivize overly conservative (or collusive) bidding strategies among learning agents.

A greater number of bidders improves performance in first-price auctions when agents rely on Q-learning, reducing the revenue gap relative to second-price. However, the opposite emerges with LinUCB bandits, where more participants appear to amplify underbidding. This divergence suggests that standard economic intuition—where increased competition drives up bids—may be upended by different algorithmic forms of learning and exploration.

The Q-learning experiments reveal that a high discount factor intensifies the first-price underperformance. When agents place greater weight on future outcomes, they seem more motivated to shade bids aggressively in the near term, possibly hoping for improved payoffs over the long run. By contrast, second-price auctions do not appear as sensitive to this temporal consideration, maintaining relatively stable performance across different discount-factor regimes.


The manner in which agents explore significantly alters the extent of first-price losses. Boltzmann exploration, which selects actions with probabilities weighted by current value estimates, tends to mitigate underbidding. In contrast, \(\varepsilon\)-greedy exploration—where agents pick the best-known action or otherwise randomize uniformly—reinforces strategic conservatism in first-price auctions and leads to lower overall revenue.

In Q-learning, synchronous updates that adjust the action-value function for all actions—rather than solely the chosen one—help curb the detrimental effects of first-price. This more thorough learning process appears to limit persistent miscalibrations, ensuring that alternative bidding strategies are not neglected. Asynchronous updates, by updating only the chosen bid each round, permit entrenched underbidding equilibria to emerge more readily.

Switching from Q-learning to a bandit framework (particularly LinUCB) was expected to offer more “sophisticated” or “efficient” exploration. Yet, our results show that bandit-based bidders can produce more polarized outcomes, including extremely low-revenue equilibria and frequent no-sales. Rather than improving overall seller payoffs, this more advanced contextual approach may exacerbate the strategic gap between first- and second-price auctions.

Though we introduced affiliated valuations via the parameter \(\eta\), it did not significantly alter the core first- versus second-price revenue gap in any of the experiments. Whether values were purely private (\(\eta=0\)) or close to common (\(\eta=1\)), learning agents displayed similar bidding patterns across auction formats. In practice, this implies that the mechanism choice may overshadow the importance of valuation interdependence in shaping long-run auction outcomes under learning.

Reserve prices show limited direct impact on final revenue but can reduce bidding volatility under first-price auctions. By disqualifying very low bids, reserves effectively raise the floor of competition, discouraging extreme shading and limiting the range of payoffs. Nonetheless, such price floors cannot by themselves resolve the fundamental underperformance of first-price formats revealed in these experiments.

Taken together, these findings point to a central conclusion: when bidders are learning autonomously, second-price auctions tend to outperform first-price auctions across a wide variety of settings and parameters. Even so, the nature of the learning algorithm—Q-learning versus contextual bandits—strongly influences the severity and form of underbidding behaviors. From a practical standpoint, designers seeking robust revenue outcomes in algorithmic bidding environments may wish to favor second-price mechanisms or employ additional tools (e.g., carefully tuned reserves, offer information so that synchronous updating can take place) that limit first-price collusion.

\paragraph{Budget Constraints as a Structural Moderator.}
Experiment~4 reveals a fourth moderating force: spending constraints. Budget-constrained pacing agents converge substantially faster than unconstrained Q-learners or LinUCB bandits---median convergence occurs around 1{,}000 rounds versus 22{,}730 rounds for the bandit experiment---suggesting that the hard budget cap forces early settlement into stable bidding patterns. This convergence acceleration parallels the role of high exploration parameters in earlier experiments: both introduce a form of forced commitment that prevents indefinite experimentation. The dominant factor across all nine response variables is \emph{budget tightness}: tighter budgets raise auction revenue, mirroring optimal auction theory's prediction that binding capacity constraints increase allocative pressure (Myerson 1981). The algorithm choice (PID vs.\ multiplicative) is the second strongest factor, with PID generating approximately 35\% higher revenue overall. Crucially, the \emph{algorithm $\times$ budget tightness} interaction reveals that the PID advantage is largest precisely when budgets are tight---PID's integral correction allows finer pacing control under binding constraints, whereas the multiplicative algorithm's dual variable can oscillate near the budget boundary. This dynamic is consistent with the tractability results in Conitzer et al.\ (2022): first-price pacing equilibria (FPPE) are polynomial-time computable, and PID converges toward them more reliably. Aggressiveness in pacing plays a structurally analogous role to exploration in Q-learning: higher aggressiveness raises revenue in first-price auctions by preventing excessive bid shading, the same mechanism by which Boltzmann exploration reduces collusion in Experiments~1 and~2. Taken together, these results extend the core conclusion: budget constraints do not eliminate the first-price underperformance, but they substantially attenuate it through forced pacing discipline---a finding with direct implications for programmatic advertising markets where budget-constrained DSPs participate in repeated first-price auctions.