\section{Discussion and Generalisability}
\label{sec:discussion}

\subsection{First-Price Underperformance Across All Settings}

The most robust empirical finding across all four experiments is that first-price auctions systematically yield lower revenue than second-price auctions when bidders are autonomous learning agents. This pattern persists regardless of learning algorithm (Q-learning, LinUCB bandits, or pacing controllers), valuation structure (constant versus affiliated), or budget regime (unconstrained versus constrained). Table~\ref{tab:cross_exp_revenue} quantifies the magnitude and consistency of this effect.

\begin{table}[H]
\centering
\caption{First-Price Revenue Gap Across All Experiments}
\label{tab:cross_exp_revenue}
\begin{tabular}{lllccc}
\toprule
Experiment & Algorithm & Valuations & FPA Revenue & SPA Revenue & Gap (\%) \\
\midrule
E1 & Q-learning & Constant & 0.718 & 0.839 & $-14.4$ \\
E2 & Q-learning & Affiliated & 0.546 & 0.549 & $-0.5$ \\
E3 & LinUCB & Affiliated & 0.327 & 0.566 & $-42.3$ \\
E4 & Pacing (PID/Mult) & Affiliated & 0.445 & 0.495 & $-10.0$ \\
\bottomrule
\end{tabular}
\end{table}

The \emph{direction} of the effect is universal: first-price always underperforms. The \emph{magnitude} varies substantially by context. The gap is smallest in Experiment~2 ($-0.5$\%), where Q-learning agents with affiliated valuations achieve near-parity between auction formats. The gap is largest in Experiment~3 ($-42.3$\%), where LinUCB bandits produce frequent zero-revenue equilibria in first-price auctions. Budget-constrained pacing (Experiment~4) attenuates the gap to $-10.0$\%, suggesting that spending constraints impose a form of discipline that partially mitigates strategic bid shading.

This pattern directly contradicts the revenue equivalence theorem (Myerson, 1981), which predicts identical expected revenues across auction formats under risk-neutral bidders with independent private values. The systematic first-price shortfall arises because learning agents lack the strategic sophistication to compute and commit to theoretically optimal bid functions. Instead, they converge to locally stable equilibria characterised by excessive bid shading, a form of emergent algorithmic collusion requiring no explicit communication or coordination.

\subsection{Exploration and Aggressiveness as Moderators}

Across all four experiments, factors that promote commitment to higher bids consistently improve first-price auction performance. The specific mechanism varies by algorithm, but the structural effect is identical: preventing agents from settling into conservative, collusive equilibria.

\subsubsection{Q-Learning (Experiments~1--2)}

Boltzmann exploration, which selects actions probabilistically based on softmax-weighted Q-values, reduces first-price losses by ensuring that high-bid actions receive occasional reinforcement even when they are not strictly greedy. In contrast, $\varepsilon$-greedy exploration (where agents either take the greedy action or randomise uniformly) reinforces underbidding by treating all exploratory bids symmetrically. A high discount factor ($\gamma$) intensifies first-price underperformance by encouraging agents to shade bids aggressively in the short term while waiting for improved long-run payoffs. Synchronous updates, which adjust Q-values for all actions rather than only the chosen action, curb first-price losses by preventing persistent miscalibrations where alternative bidding strategies are neglected.

\subsubsection{Pacing Controllers (Experiment~4)}

The aggressiveness parameter in pacing algorithms plays a structurally analogous role to exploration in Q-learning. Higher aggressiveness raises revenue in first-price auctions by preventing excessive bid shading: aggressive agents commit larger fractions of their budget early, forcing competitors to respond with higher bids or risk losing repeatedly. The parallel is precise: both Boltzmann exploration in Experiments~1--2 and high aggressiveness in Experiment~4 introduce forced commitment mechanisms that destabilise low-bid equilibria.

\subsubsection{LinUCB Bandits (Experiment~3)}

Higher exploration in LinUCB (controlled by the confidence parameter $c$) \emph{exacerbates} rather than mitigates collusion, diverging sharply from Q-learning. This suggests that contextual exploration does not automatically improve seller outcomes. LinUCB's optimism-based exploration may reinforce risk-averse bidding by inflating uncertainty estimates around aggressive actions that rarely win. The result is counterintuitive: the algorithm designed for more efficient exploration produces worse seller outcomes than the simpler Q-learning approach.

The unifying insight across all three algorithm classes is that exploration \emph{mechanisms} matter more than exploration \emph{rates}. Mechanisms that preserve value-weighted action selection (Boltzmann) or impose commitment pressure (aggressiveness) reduce collusion; mechanisms that introduce symmetric randomness ($\varepsilon$-greedy) or uncertainty-driven conservatism (UCB) do not.

\subsection{Convergence and Constraints}

Table~\ref{tab:cross_exp_convergence} compares convergence times across all experiments, revealing stark differences in how quickly agents settle into stable bidding patterns.

\begin{table}[H]
\centering
\caption{Convergence Time Across All Experiments (rounds)}
\label{tab:cross_exp_convergence}
\begin{tabular}{llcc}
\toprule
Experiment & Algorithm & Median & Mean \\
\midrule
E1 & Q-learning (constant) & 1{,}000 & 1{,}000 \\
E2 & Q-learning (affiliated) & 86{,}179 & 57{,}723 \\
E3 & LinUCB & 1{,}000 & 1{,}000 \\
E4 & Pacing (PID/Mult) & 1{,}014 & 4{,}279 \\
\bottomrule
\end{tabular}
\end{table}

Budget constraints act as a convergence accelerator. Pacing agents (Experiment~4) converge approximately as fast as the fastest unconstrained agents (Experiments~1 and~3) and dramatically faster than Q-learning with affiliated valuations (Experiment~2). The hard budget cap forces early settlement by limiting bid exploration once available headroom is exhausted: once an agent approaches its spending limit, further experimentation becomes prohibitively costly, inducing rapid commitment to a stable pacing policy.

The extreme variability in Experiment~2 (median 86{,}179 versus mean 57{,}723) suggests bimodal convergence: some replicates settle quickly while others exhibit prolonged oscillations. Budget-constrained pacing (Experiment~4) shows tighter convergence distributions (median 1{,}014, mean 4{,}279), consistent with the forced discipline imposed by spending limits.

Faster convergence does not guarantee higher revenue. Experiment~3 converges as quickly as Experiment~1 yet produces far lower revenues. The key determinant is not convergence speed per se but rather \emph{which equilibrium} agents converge to, a function of exploration mechanism, state representation, and budget constraints.

\subsection{How Algorithm Class Shapes the Revenue Gap}

The first-price revenue penalty manifests through qualitatively different mechanisms across the three algorithm classes, yet all share a common failure: no algorithm learns to implement the theoretically optimal bid function in first-price auctions.

The magnitude of the gap varies by an order of magnitude. Q-learning with affiliated valuations (Experiment~2) narrows the first-price shortfall to under 1\%, while LinUCB bandits (Experiment~3) widen it to over 40\%. This variation is informative: it reveals that the revenue gap is not an inherent property of first-price auctions but rather a consequence of how specific learning dynamics interact with the payment rule. Q-learning agents, despite their simplicity, can partially offset bid shading through synchronous updates and richer state representations that encode competitive information. In contrast, LinUCB's optimism-based exploration amplifies conservative bidding by inflating uncertainty around aggressive actions, producing frequent zero-revenue equilibria that Q-learning avoids entirely.

A striking cross-experiment comparison concerns the role of competition. Under Q-learning (Experiments~1--2), more bidders improve first-price revenue by introducing competitive pressure that counteracts bid-shading incentives. Under LinUCB (Experiment~3), this relationship reverses: additional bidders worsen first-price performance. The reversal suggests that optimism-based exploration, which works well in single-agent settings, can amplify underbidding when multiple agents simultaneously inflate their uncertainty estimates and retreat to conservative bids.

Budget-constrained pacing (Experiment~4) introduces a qualitatively distinct form of bid suppression. Unlike the strategic collusion observed in Experiments~1--3, where agents shade bids below competitive levels to extract surplus, pacing agents suppress bids because spending constraints force them to ration across auctions. The distinction matters for policy: strategic collusion represents a market failure amenable to mechanism design interventions, while budget-mediated suppression reflects rational resource allocation under constraints. The first-price gap in Experiment~4 ($-10.0$\%) falls between the Q-learning and bandit extremes, consistent with budget constraints imposing partial discipline that limits both aggressive bidding and extreme shading.

The common thread across all algorithm classes is that learning agents converge to locally stable equilibria characterised by insufficient aggression in first-price auctions. The specific mechanism varies, from Q-value underestimation to uncertainty-driven conservatism to budget-induced rationing, but the outcome is universal: no algorithm class tested here reliably discovers revenue-maximising bid functions without structural intervention.

\subsection{Winner Concentration and Collusion Structure}

Winner entropy, defined as the Shannon entropy of the empirical winner distribution, distinguishes between two collusion modes: symmetric bid suppression (high entropy, where multiple bidders share wins at reduced prices) and asymmetric predation (low entropy, where one bidder dominates at the expense of others). Across all experiments with sufficient statistical power, first-price auctions consistently produce higher winner entropy than second-price auctions: the effect is significant in Experiment~2 ($+0.183$, $p = 0.008$), Experiment~3 ($+0.046$, $p = 0.008$), and Experiment~4 ($+0.037$, $p < 0.001$). This pattern indicates that the bid suppression under first-price auctions is symmetric: all agents shade bids similarly, preserving a roughly equitable rotation of winners while collectively reducing prices paid to the seller. Second-price auctions, by contrast, tend toward lower entropy, with one or two bidders winning disproportionately. In Experiment~4, the bidder objective exerts a stronger effect on entropy ($-0.101$, $t = -10.9$) than auction format: utility-maximizing agents produce more concentrated winner distributions because the additional term in their bid formula amplifies heterogeneity across bidders with different dual variables. Market thickness is the dominant factor in Experiment~4 ($+0.287$, $t = 31.0$), as expected from information-theoretic bounds on entropy. These findings refine the characterisation of algorithmic collusion from a simple revenue reduction to a structural pattern: first-price collusion operates through coordinated restraint among symmetric participants rather than through market dominance by a single agent.

\subsection{Factors with Minimal Impact}

\subsubsection{Affiliation ($\eta$)}

Experiments~2, 3, and~4 all include the affiliation parameter $\eta \in \{0, 1\}$ as a factorial treatment, controlling whether valuations are purely private or near-common values. Across all three experiments and all response variables, $\eta$ exhibits negligible main effects and minimal interactions. Whether values are independent or highly correlated, learning agents display similar bidding patterns across auction formats. The mechanism choice overshadows valuation interdependence in shaping long-run outcomes under learning. This diverges from classical auction theory, where common-value components induce winner's curse concerns that should theoretically alter optimal bidding strategies. The negligible $\eta$ effect suggests that learning agents do not internalise winner's curse logic; instead, they converge to equilibria determined primarily by auction rules and exploration mechanisms, not valuation structure.

\subsubsection{Reserve Prices}

Experiments~1, 3, and~4 include reserve prices as factorial treatments. Across all three, reserve prices show limited direct impact on revenue but modest effects on price volatility. Reserves reduce bidding volatility by disqualifying very low bids, effectively raising the floor of competition and discouraging extreme shading. However, reserve prices cannot by themselves resolve the fundamental first-price underperformance: even with binding reserves, first-price auctions systematically yield lower revenues than second-price auctions with equivalent reserve levels. The weak reserve-price effects are consistent with the interpretation that algorithmic collusion arises from learning dynamics rather than strategic calculation. A reserve price alters the action space but does not change the underlying reinforcement structure that drives agents toward conservative equilibria in first-price auctions.

\subsection{External Validity}

The results presented here are likely to hold in settings characterised by repeated interactions where agents participate in thousands to hundreds of thousands of auction rounds, autonomous learning where bidders use algorithmic policies without human oversight, independent bidders without explicit communication or coordination, both private and affiliated valuation structures, and sealed-bid formats with or without reserve prices. These conditions closely approximate real-world programmatic advertising markets, where demand-side platforms submit bids autonomously across millions of daily impressions, budget constraints bind frequently, and auction formats vary by exchange. The first-price underperformance documented here suggests that sellers in such markets may systematically benefit from adopting second-price mechanisms.

Several contexts may produce qualitatively different outcomes. Few-shot or one-shot auctions, where strategic sophistication may dominate learning dynamics, are outside the scope of these findings. Human bidders introduce behavioural biases, risk aversion, and strategic reasoning that reinforcement learning models do not capture. Explicit collusion through communication channels or coordinated strategies could produce collusive outcomes in both auction formats. Alternative auction formats such as ascending (English), descending (Dutch), or combinatorial auctions involve different information revelation and strategic considerations. Settings with externalities or budget pooling, where bidder values or constraints are interdependent across auctions, may exhibit different convergence properties. The experiments deliberately abstract away from these factors to isolate the core effect of learning algorithms and auction mechanisms.

\subsection{Practical Implications}

The systematic first-price underperformance across all experiments carries direct implications for auction design in algorithmic markets. When bidders are autonomous learning agents, second-price auctions robustly outperform first-price auctions across diverse settings, algorithms, and parameter regimes. Sellers seeking stable, high revenues should favour second-price mechanisms or implement structural interventions (such as binding budget constraints (Experiment~4), enforced synchronous updating (Experiments~1--2), or carefully tuned reserves) that limit the scope for emergent algorithmic collusion.

For platforms already committed to first-price formats, the results suggest actionable design levers: encourage or mandate aggressive pacing policies, provide richer state information to enable synchronous learning, and impose budget constraints that force early commitment. Platforms should exercise caution about adopting exploration mechanisms based on optimism or uncertainty quantification (e.g., Thompson sampling, UCB variants) without empirical validation, as Experiment~3 demonstrates that algorithmic sophistication does not guarantee seller-favourable outcomes.

From a policy perspective, the findings raise questions about market efficiency and welfare distribution in programmatic advertising. If first-price auctions systematically transfer surplus from sellers to buyers under algorithmic bidding, without corresponding efficiency gains, then the industry-wide shift toward first-price formats may have inadvertently reduced publisher revenues. Empirical validation using real auction data remains an important next step for translating these simulation findings into regulatory or platform design recommendations.
