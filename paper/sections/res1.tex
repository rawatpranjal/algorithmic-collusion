\section{Experiment I: Q-Learning under Constant Valuations}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{figures/e1_trace}
  \caption{Representative learning trajectory for a single trial of Experiment~1 (first-price auction, 2~bidders, Boltzmann exploration, 10{,}000 episodes). Top: rolling-mean revenue converging toward the BNE prediction. Middle: per-bidder mean bids evolving over time. Bottom: exploration temperature decay schedule.}
  \label{fig:e1_trace}
\end{figure}

Experiment~1 deploys Q-learning agents with constant valuations ($v=1$) in a $2^{11-1}$ Resolution~V half-fraction spanning 11 factors and 2{,}048 observations. Despite identical true valuations across all bidders, average revenues in the final 1{,}000 episodes range from approximately 0.3 to 1.0, revealing substantial variability driven by the interaction of learning parameters and auction format. The factorial analysis decomposes this variability into systematic effects attributable to individual factors and their interactions.

\subsection{Revenue and Seller Regret}

Auction type is the dominant factor affecting both revenue and seller regret. Table~\ref{tab:exp1_ranked_rev} ranks significant effects for revenue by absolute $t$-statistic. Auction type yields the largest $t$-statistic, followed by exploration strategy and asynchronous updating. First-price auctions consistently reduce revenue and increase regret relative to second-price auctions, as confirmed by the main effects plots (Figures~\ref{fig:e1_main_rev} and~\ref{fig:e1_main_reg}).

\input{tables/exp1_ranked_rev}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\textwidth]{figures/e1_main_rev}
  \caption{Experiment~1: Main effects plot for average revenue. First-price auctions ($+1$) reduce revenue relative to second-price ($-1$).}
  \label{fig:e1_main_rev}
\end{figure}

\input{tables/exp1_ranked_reg}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\textwidth]{figures/e1_main_reg}
  \caption{Experiment~1: Main effects plot for seller regret. First-price auctions increase regret across all factor configurations.}
  \label{fig:e1_main_reg}
\end{figure}

Exploration strategy is the second most important factor. The main effects plots show that $\varepsilon$-greedy exploration intensifies first-price losses relative to Boltzmann exploration, which uses softmax-weighted Q-values to select actions probabilistically. Boltzmann exploration provides a more controlled mechanism that ensures high-bid actions receive occasional reinforcement even when they are not strictly greedy, thereby mitigating aggressive underbidding. Asynchronous Q-updates rank third in importance, increasing first-price losses compared to synchronous updates. Synchronous learning dampens the detrimental impact of first-price auctions by maintaining more uniform knowledge updates across all possible actions and bidders.

The number of bidders moderates the auction type effect through a significant two-way interaction: as the number of bidders increases, the revenue penalty from first-price auctions shrinks, consistent with the economic intuition that competitive pressure partially offsets strategic underbidding. Figure~\ref{fig:e1_int_rev} displays the top interaction effects for revenue, showing the non-additive interplay between auction format and other design factors.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\textwidth]{figures/e1_int_rev}
  \caption{Experiment~1: Interaction plot for average revenue, showing the top two-way interactions. Non-parallel lines indicate that the effect of one factor depends on the level of another.}
  \label{fig:e1_int_rev}
\end{figure}

\subsection{Price Volatility}

Although auction type has a minimal direct effect on price volatility, Table~\ref{tab:exp1_ranked_vol} reveals that volatility depends significantly on exploration strategy and update mode. Agents using $\varepsilon$-greedy exploration or asynchronous Q-learning updates exhibit substantially higher price volatility, even when auction type itself does not raise volatility on average. The main effects plot (Figure~\ref{fig:e1_main_vol}) confirms these directional effects. Increasing the number of bidders also modestly increases price volatility under first-price auctions, pushing against the intuition that more competition always stabilises outcomes.

\input{tables/exp1_ranked_vol}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\textwidth]{figures/e1_main_vol}
  \caption{Experiment~1: Main effects plot for price volatility. Exploration strategy and update mode are the primary drivers.}
  \label{fig:e1_main_vol}
\end{figure}

\subsection{Model Fit and Significant Effects}

\input{tables/exp1_model_fit}

\input{tables/exp1_significant}

\subsection{Summary}

First-price auctions are associated with substantially lower final revenues and higher seller regret in the constant-valuation Q-learning setting. These effects are buffered by having more bidders but intensified by $\varepsilon$-greedy exploration and asynchronous updates. Boltzmann exploration and synchronous learning both help curtail first-price losses by introducing value-weighted randomisation and uniform knowledge updates, respectively. Price volatility does not increase under first-price on average but does when agents use asynchronous updating or $\varepsilon$-greedy exploration. From the seller's perspective, these results are unambiguous: first-price auctions fare poorly when Q-learning algorithms determine bids.
