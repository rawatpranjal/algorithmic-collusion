\section{Introduction}

Intelligent algorithms are rapidly taking over real-time computerized auctions and markets in areas such as online marketplaces for pre-owned items, display advertising, sponsored search, financial trading, electricity, transportation, and public procurement. Significant concerns arise about the efficiency of auctions—originally tailored to human participants—under this new regime of algorithmic bidding. For instance, in large-scale advertising exchanges like Google AdSense, even minor inefficiencies or bid suppression can cause million-dollar losses. Recent work on algorithmic collusion in auctions has established that reinforcement-learning agents can spontaneously converge to sub-competitive bidding patterns. Calvano et al. (2020) demonstrate this phenomenon in pricing games, while Klein (2021) extends the analysis to sequential pricing with Q-learning. Banchio and Skrzypacz (2022) examine first- versus second-price auctions, finding that the former is more prone to bid suppression under simple Q-learning. However, these studies focus on narrow settings (constant valuations, small numbers of bidders, simple exploration mechanisms) and do not systematically parse how algorithmic factors (learning rates, discount factors, synchronization modes, budget constraints) amplify or mitigate tacit collusion.

This leaves open important questions: Do these findings hold when bidders have stochastic, possibly affiliated valuations? Are the results sensitive to the fine details of the algorithm? Are conclusions sensitive to different ways of exploring or initializing Q-values? Would the results change if algorithms explored the bid space in a more efficient way? What is the role of competitive pressure and informtion disclosures? Empirical data on real-world algorithmic auctions are fairly inaccessible, as most auctions are proprietary. Theoretical work also faces challenges, since modeling high-dimensional dynamic systems of Q-learning agents is analytically intractable. Indeed, if they were transparent then we would not have to wait until 2017 for Q-learning to attain superhuman prowess in chess. Existing theoretical papers typically focus on small state/action spaces and very crude learning algorithms.

This is where experimental work can come in and shed light on machine behaviour in important settings. However, experimental work in this area has also been partial in scope, rarely examining multiple interacting factors (e.g., discounting, asynchronous updates, alternative exploration strategies). This paper adopts a rigorous statistical approach and documents important facts about algorithmic learning in repeated auctions. A parallel literature examines budget-constrained bidding and pacing algorithms in online advertising auctions. Conitzer et al. (2022) characterize pacing equilibria in first-price auction markets and show that multiplicative pacing can lead to inefficient outcomes. Balseiro and Gur (2019) develop dual-based pacing algorithms that converge to near-optimal spending policies, though their analysis assumes stationary environments. Recent work on the price of anarchy in repeated auctions quantifies welfare losses when bidders optimize inter-temporally under budget constraints. This literature focuses on algorithm efficiency and convergence properties but does not examine collusion or strategic bid suppression. This paper addresses the gap by conducting a fully randomized factorial experiment comprising four experiments, each involving hundreds of independent trials and up to 100,000 simulated auctions per trial. Bidders apply reinforcement learning or bandit-based exploration under varied institutional elements (e.g., private vs.\ affiliated values, number of bidders, reserve prices) and algorithmic parameters (e.g., discount factors, Q-learning rates, synchronous vs.\ asynchronous updates, different exploration rules).

This paper offers one of the most comprehensive experimental studies of algorithmic learning in sealed-bid auctions to date, examining an exceptionally wide range of parameters and outcomes. We systematically investigate Q-learning, contextual bandits, and budget-constrained pacing algorithms, incorporate affiliated values to capture the continuum between private and common values, and measure not only revenue and regret but also price volatility, no-sale rates, and winner identity patterns. By varying reserve prices, the number of bidders, exploration schemes (Boltzmann vs.\ $\varepsilon$-greedy, synchronous vs.\ asynchronous Q-learning), and budget constraints, we uncover robust heterogeneity and interactions between auction formats and algorithmic details. More broadly, this paper demonstrates how factorial design methodology can efficiently analyze machine behavior in controlled environments, yielding interpretable main effects and interaction terms that generalize across learning paradigms.

Across all four experiments, I establish that first-price auctions consistently exhibit coordinated bid suppression, while second-price auctions align winning bids more closely with actual valuations and reduce volatility during the learning phase. This pattern is robust to valuation structure (constant vs.\ affiliated), learning algorithm (Q-learning, LinUCB, pacing controllers), and budget regime (unconstrained vs.\ constrained). The factorial analysis reveals heterogeneous treatment effects: the revenue loss from first-price auctions is magnified by fewer bidders, higher discount factors, asynchronous updating, and tighter budget constraints, while reserve prices provide partial mitigation. A distinctive feature of this paper is the systematic comparison across all four experiments to distinguish robust patterns from context-dependent effects. Section~\ref{sec:discussion} synthesizes findings across Q-learning (Experiments~1--2), contextual bandits (Experiment~3), and budget-constrained pacing (Experiment~4), identifying which mechanisms generalize across all settings and which vary by algorithmic paradigm. This cross-experiment framework reveals that first-price underperformance is universal, while the magnitude of revenue loss and the efficacy of moderating factors (exploration, competition, budget constraints) depend critically on algorithm class and valuation structure. The discussion provides quantitative comparisons of convergence speed, revenue gaps, and the role of exploration mechanisms across all experiments, establishing a taxonomy of robust versus algorithm-specific findings.
