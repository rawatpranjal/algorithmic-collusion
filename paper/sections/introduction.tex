\section{Introduction}

Intelligent algorithms are rapidly taking over real-time computerized auctions and markets in areas such as online marketplaces for pre-owned items, display advertising, sponsored search, financial trading, electricity, transportation, and public procurement. Significant concerns arise about the efficiency of auctions—originally tailored to human participants—under this new regime of algorithmic bidding. For instance, in large-scale advertising exchanges like Google AdSense, even minor inefficiencies or bid suppression can cause million-dollar losses.

Banchio and Skrzypacz (2022) first examined how reinforcement-learning agents interact in auction settings and concluded that a first-price auction is prone to collusive (or “bid-suppression”) outcomes, whereas a second-price auction is not. Their study, however, focused on constant valuations with only two or three bidders, used relatively simple exploration mechanisms, and did not thoroughly parse out how algorithmic factors (learning rates, discount factors, synchronization modes, etc.) amplify or mitigate tacit collusion. 

This leaves open important questions: Do these findings hold when bidders have stochastic, possibly affiliated valuations? Are the results sensitive to the fine details of the algorithm? Are conclusions sensitive to different ways of exploring or initializing Q-values? Would the results change if algorithms explored the bid space in a more efficient way? What is the role of competitive pressure and informtion disclosures? 

Empirical data on real-world algorithmic auctions are fairly inaccessible, as most auctions are proprietary. Theoretical work also faces challenges, since modeling high-dimensional dynamic systems of Q-learning agents is analytically intractable. Indeed, if they were transparent then we would not have to wait until 2017 for Q-learning to attain superhuman prowess in chess. Existing theoretical papers typically focus on small state/action spaces and very crude learning algorithms. 

This is where experimental work can come in and shed light on machine behaviour in important settings. However, experimental work in this area has also been partial in scope, rarely examining multiple interacting factors (e.g., discounting, asynchronous updates, alternative exploration strategies). This paper adopts a rigorous statistical approach and documents important facts about algorithmic learning in repeated auctions. 

This paper addresses the gap in the literature by conducting a fully randomized factorial experiment comprising three sequential designs, each involving 500 independent trials and up to 100,000 simulated auctions per trial. Bidders apply reinforcement learning or bandit-based exploration under varied institutional elements (e.g., private vs.\ affiliated values, number of bidders, reserve prices) and algorithmic parameters (e.g., discount factors, Q-learning rates, synchronous vs.\ asynchronous updates, different exploration rules). 

\textbf{Contribution.} In this paper, we offer one of the most comprehensive experimental studies of algorithmic learning in sealed-bid auctions to date, examining an exceptionally wide range of parameters and outcomes. We systematically investigate both Q-learning and bandit-based approaches, incorporate affiliated values to capture the continuum betwee private and common values, and measure not only revenue and regret but also price volatility, no-sale rates, and winner identity patterns. By varying reserve prices, the number of bidders, and distinct exploration schemes (e.g., Boltzmann vs.\ $\varepsilon$-greedy, synchronous vs.\ asynchronous Q-learning, and linear bandits), we uncover robust heterogeneity and interactions between auction formats and algorithmic details. More broadly, this paper offers a statistical approach to analysing machine behaviour in a controlled environment in an efficient manner. 

We first re-establish that a first-price auction, in which the winner pays her own bid, consistently exhibits coordinated bid suppression. In contrast, the second-price auction aligns winning bids more closely with actual valuations, reduces volatility during the learning phase, and often speeds up convergence. The second-price design appears robust to further complexity, such as the introduction of partial common values via affiliation or more sophisticated exploration algorithms. We also obtain heterogeneous treatment effects i.e. how other factors influence the impact of payment rules on seller reserves. Here I employ state of the art machine learning estimators to show that the impact of moving to second-price is magnified by fewer bidders, higher discount factors, and asynchronous updating.

\paragraph{Cross-Experiment Synthesis.}
A distinctive feature of this paper is the systematic comparison across all four experiments to distinguish robust patterns from context-dependent effects. Section~\ref{sec:discussion} synthesizes findings across Q-learning (Experiments~1--2), contextual bandits (Experiment~3), and budget-constrained pacing (Experiment~4), identifying which mechanisms generalize across all settings and which vary by algorithmic paradigm. This cross-experiment framework reveals that first-price underperformance is universal, while the magnitude of revenue loss and the efficacy of moderating factors (exploration, competition, budget constraints) depend critically on algorithm class and valuation structure. The discussion provides quantitative comparisons of convergence speed, revenue gaps, and the role of exploration mechanisms across all experiments, establishing a taxonomy of robust versus algorithm-specific findings. 
