\section{Statistical Inference}

\subsection{Factorial Design Framework}

We employ $2^k$ factorial designs to systematically explore the parameter space of each experiment. Every factor is coded as $x_i \in \{-1, +1\}$\footnote{Effects coding ($\{-1, +1\}$) differs from indicator (dummy) coding ($\{0, 1\}$). Under effects coding, the intercept $\beta_0$ equals the grand mean of all observations, and each $\beta_j$ measures the deviation of a factor level from that grand mean. This yields orthogonal contrasts in balanced designs, so that main effects and interactions are estimated independently. Indicator coding would confound the intercept with the reference level and introduce correlations between estimators in factorial models.}, representing its low and high levels respectively. This coding ensures orthogonality: factor estimates are uncorrelated, and the design provides balanced variance across the entire experimental region. The balanced structure guarantees that each main effect and two-way interaction can be estimated independently of all others, enabling clean attribution of outcome variation to specific factors.

Experiments~1 and~2 each use a $2^{11-1}$ Resolution~V half-fraction with 11 factors and 1{,}024 design cells; they share eight core factors and differ in three (Experiment~1 includes bid-grid resolution, information feedback, and decay schedule, while Experiment~2 substitutes the affiliation parameter $\eta$ and two state-information indicators). Experiment~3 uses a $2^8$ full factorial with 8 factors and 256 cells, reflecting the smaller parameter space of the LinUCB contextual bandit. Experiment~4 uses a $2^{9-1}$ Resolution~IX half-fraction with 9 factors and 256 base cells, replicated three times to produce 768 observations. Each design cell in Experiments~1--3 is replicated twice, enabling pure error estimation and lack-of-fit testing. Total observations range from 512 (Experiment~3) to 2{,}048 (Experiments~1 and~2).

\subsection{Estimation}

For each response variable $Y$ (e.g., average revenue, seller regret, convergence time), we fit a linear model with main effects and all two-way interactions via ordinary least squares (OLS):
\begin{align}
  Y_i = \beta_0 + \sum_{j=1}^{k} \beta_j\, x_{ji} + \sum_{1 \le j < l \le k} \beta_{jl}\, x_{ji}\, x_{li} + \varepsilon_i,
  \label{eq:ols}
\end{align}
where $x_{ji} \in \{-1, +1\}$ is the coded level of factor $j$ in observation $i$, $\beta_j$ represents the main effect of factor $j$, and $\beta_{jl}$ captures the two-way interaction between factors $j$ and $l$. Under the coded parameterisation, $\beta_j$ equals half the change in mean response when factor $j$ moves from its low to its high level, holding all other factors at their centre values. Similarly, $\beta_{jl}$ equals half the difference in the effect of factor $j$ between the two levels of factor $l$.

We use Type~III ANOVA decomposition to assess the marginal contribution of each term, testing each coefficient against the null $H_0\!: \beta = 0$ via the $t$-statistic $\hat{\beta}/\text{SE}(\hat{\beta})$. Model adequacy is validated by comparing OLS $R^2$ to a gradient-boosted machine (LightGBM) $R^2$ trained with five-fold cross-validation: if the gap is less than 0.05, the linear model with two-way interactions captures most of the signal without requiring higher-order terms or nonlinear transformations.

\subsection{Fractional Factorial Designs and Aliasing}

Experiments~1, 2, and~4 use fractional factorial designs to reduce experimental burden. The key trade-off is aliasing: some higher-order interactions become confounded with lower-order terms.

\subsubsection{Resolution~V (Experiments~1 and~2)}

In a Resolution~V\footnote{In a Resolution~$R$ design, no $p$-factor interaction is aliased with any interaction of fewer than $R - p$ factors. Resolution~V therefore guarantees that main effects are free of two-way interaction bias and two-way interactions are free of other two-way interaction bias.} design, no main effect is aliased with any interaction of fewer than four factors, and no two-way interaction is aliased with any interaction of fewer than three factors. This ensures that all main effects and two-way interactions are estimable without bias from three-way terms, which are assumed negligible under effect sparsity.

\subsubsection{Resolution~IX (Experiment~4)}

Resolution~IX\footnote{At Resolution~IX, even four-way interactions cannot bias main effects or two-way interactions, making the fractional design virtually equivalent to a full factorial for the effects of interest.} provides near-complete information: main effects are unaliased with interactions of up to eight factors. This extremely high resolution means that even four-way interactions cannot bias the estimation of main effects or two-way interactions, making the fractional design nearly equivalent to a full factorial for the effects of interest.

The assumption underlying both fractional designs is \emph{effect sparsity}: most variation in the response is explained by main effects and two-way interactions, with three-way and higher interactions contributing negligibly. We validate this assumption using LASSO variable selection and nonparametric model comparison.

\subsection{Robustness Checks}

\subsubsection{Inference Corrections}

We compute HC3 robust standard errors (MacKinnon and White, 1985) to account for non-constant error variance across the design space. Comparing OLS standard errors to HC3 robust standard errors, we verify that significance claims hold under heteroscedasticity. Across all experiments, fewer than 5\% of effects change significance status under HC3 correction.

With $k$ main effects, $\binom{k}{2}$ two-way interactions, and $m$ response variables, each experiment involves hundreds of hypothesis tests. For example, Experiment~2 tests 66 terms across 6 responses for a total of 396 tests. We apply Holm--Bonferroni sequential correction (Holm, 1979) to control the family-wise error rate at $\alpha = 0.05$. Key findings, including the auction type main effect and the auction type $\times$ exploration interaction, survive this stringent correction across all responses.

For the top~10 effects by absolute $t$-statistic in each response, we compute Rademacher wild bootstrap $p$-values (1{,}000 iterations) to validate inference under minimal distributional assumptions. Bootstrap $p$-values align closely with HC3 asymptotic $p$-values (differences below 0.01), confirming robustness.

\subsubsection{Model Adequacy}

With two replicates per cell, we decompose the residual sum of squares into pure error (within-cell variation) and lack of fit (deviation of cell means from model predictions). The $F$-test $\text{MS}_{\text{LOF}} / \text{MS}_{\text{PE}}$ assesses whether the linear model with two-way interactions adequately fits the data. Non-significant $p$-values ($p > 0.10$) across all experiments validate model adequacy.

We compute leave-one-out cross-validated $R^2$ using the PRESS statistic:
\begin{align}
  \text{PRESS} = \sum_{i=1}^{n} \left( \frac{e_i}{1 - h_{ii}} \right)^{\!2}, \qquad
  \text{Pred-}R^2 = 1 - \frac{\text{PRESS}}{\text{SS}_{\text{Total}}},
  \label{eq:press}
\end{align}
where $e_i$ is the $i$-th ordinary residual and $h_{ii}$ is the $i$-th diagonal element of the hat matrix. A gap between $R^2$ and Pred-$R^2$ smaller than 0.10 indicates minimal overfitting. Across all experiments, gaps are below 0.05, confirming that models generalise well to held-out observations.

Gradient-boosted machines (LightGBM, 200 trees, maximum depth~4) are fit using five-fold cross-validation to establish a nonparametric upper bound on achievable $R^2$. If OLS $R^2$ is within 0.05 of LightGBM $R^2$, we conclude that the linear model with two-way interactions captures most of the signal and that higher-order or nonlinear terms contribute negligibly. Across all experiments and responses, OLS achieves 90--98\% of LightGBM $R^2$, validating model adequacy.

\subsubsection{Variable Selection and Power}

We fit five-fold cross-validated LASSO models with regularisation parameter $\lambda$ chosen to minimise mean squared error. Surviving variables are compared to OLS significance: in all experiments, LASSO retains auction type, exploration, and number of bidders, corroborating OLS effect selection. Heredity is verified by checking that no interaction survives whose parent main effects were dropped.

We compute minimum detectable effects (MDE) at 80\% power and $\alpha = 0.05$ for balanced $2^k$ designs:
\begin{align}
  \text{MDE}_{\text{main}} = \bigl(t_{\text{crit}} + t_{0.80}\bigr) \times \frac{\hat{\sigma}}{\sqrt{n}},
  \label{eq:mde}
\end{align}
where $t_{\text{crit}}$ is the critical value at $\alpha/2$, $t_{0.80}$ is the 80th percentile of the $t$-distribution, $\hat{\sigma}$ is the estimated residual standard deviation, and $n$ is the total number of observations. MDEs range from 2--5\% of the mean response, indicating that the designs have sufficient power to detect practically meaningful effects.

\subsection{Diagnostic Visualisations}

Four types of diagnostic plots accompany each response variable. Pareto charts rank effects by absolute $t$-statistic in descending order, with effects surpassing the critical threshold $t_{\alpha/2,\,\text{df}}$ shown in red, providing a visual hierarchy of effect importance. Main effects plots display the mean response at the low ($-1$) and high ($+1$) levels of each factor; steeper slopes correspond to larger $|\beta_j|$ values. Interaction plots show the mean response across the four combinations $(x_j, x_l) \in \{(-1,-1), (-1,+1), (+1,-1), (+1,+1)\}$ for the top six interactions by $|t|$-statistic; non-parallel lines indicate that the effect of one factor depends on the level of another. Half-normal probability plots display $|\hat{\beta}_j|$ against expected order statistics from a half-normal distribution, separating active effects (large departures from the reference line) from noise (points following the line). Residual diagnostics include quantile--quantile plots assessing normality and residuals-versus-fitted plots checking for heteroscedasticity and nonlinearity.

\subsection{Reporting}

All results report OLS coefficients with HC3 standard errors and Holm--Bonferroni corrected $p$-values. Effect sizes are interpreted as practical significance (magnitude relative to mean response) in addition to statistical significance ($p$-value threshold). Model adequacy is summarised via $R^2$, Pred-$R^2$, LightGBM $R^2$, and lack-of-fit $p$-value. All effects reported as statistically significant in the results sections survive multiple testing correction, heteroscedasticity correction, and nonparametric model comparison (LightGBM gap below 0.05).
