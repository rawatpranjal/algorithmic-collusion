\section{Statistical Inference}
\label{sec:inference}

\subsection{Factorial Design Framework}

We employ $2^k$ factorial designs to systematically explore the parameter space of each experiment. Every factor is coded as $x_i \in \{-1, +1\}$\footnote{Effects coding ($\{-1, +1\}$) differs from indicator (dummy) coding ($\{0, 1\}$). Under effects coding, the intercept $\beta_0$ equals the grand mean of all observations, and each $\beta_j$ measures the deviation of a factor level from that grand mean. This yields orthogonal contrasts in balanced designs, so that main effects and interactions are estimated independently. Indicator coding would confound the intercept with the reference level and introduce correlations between estimators in factorial models.}, representing its low and high levels respectively. This coding ensures orthogonality: factor estimates are uncorrelated, and the design provides balanced variance across the entire experimental region. The balanced structure guarantees that each main effect and two-way interaction can be estimated independently of all others, enabling clean attribution of outcome variation to specific factors.

Experiment~1 uses a $2^{11-1}$ Resolution~V half-fraction with 11 factors and 1{,}024 design cells, replicated twice for 2{,}048 observations. Experiment~2 uses a $3 \times 2^3$ mixed-level design with 4 factors (3 binary plus the three-level affiliation parameter $\eta$) and 24 cells, replicated twice for 48 observations. Experiment~3 uses a $3 \times 2^7$ mixed-level design with 8 factors (7 binary plus $\eta$) and 384 cells, replicated twice for 768 observations. Experiment~4 uses a $2^3$ full factorial with 3 factors and 8 cells, each replicated across 50 independent seeds for 400 observations. Replication in all experiments enables pure error estimation and lack-of-fit testing.

\subsection{Estimation}

For each response variable $Y$ (e.g., average revenue, seller regret, convergence time), we fit a linear model with main effects and all two-way interactions via ordinary least squares (OLS):
\begin{align}
  Y_i = \beta_0 + \sum_{j=1}^{k} \beta_j\, x_{ji} + \sum_{1 \le j < l \le k} \beta_{jl}\, x_{ji}\, x_{li} + \varepsilon_i,
  \label{eq:ols}
\end{align}
where $x_{ji} \in \{-1, +1\}$ is the coded level of factor $j$ in observation $i$, $\beta_j$ represents the main effect of factor $j$, and $\beta_{jl}$ captures the two-way interaction between factors $j$ and $l$. Under the coded parameterisation, $\beta_j$ equals half the change in mean response when factor $j$ moves from its low to its high level, holding all other factors at their centre values. Similarly, $\beta_{jl}$ equals half the difference in the effect of factor $j$ between the two levels of factor $l$.

We use Type~III ANOVA decomposition to assess the marginal contribution of each term, testing each coefficient against the null $H_0\!: \beta = 0$ via the $t$-statistic $\hat{\beta}/\text{SE}(\hat{\beta})$. Model adequacy is validated by comparing OLS $R^2$ to a gradient-boosted machine (LightGBM) $R^2$ trained with five-fold cross-validation: if the gap is less than 0.05, the linear model with two-way interactions captures most of the signal without requiring higher-order terms or nonlinear transformations.

\subsection{Fractional Factorial Designs and Aliasing}

Experiment~1 uses a fractional factorial design to reduce experimental burden. The key trade-off is aliasing: some higher-order interactions become confounded with lower-order terms. Experiments~2 and~3 use mixed-level designs (combining the three-level $\eta$ factor with binary factors), and Experiment~4 uses a full $2^3$ factorial, so aliasing is not a concern for these experiments.

\subsubsection{Resolution~V (Experiment~1)}

In a Resolution~V\footnote{In a Resolution~$R$ design, no $p$-factor interaction is aliased with any interaction of fewer than $R - p$ factors. Resolution~V therefore guarantees that main effects are free of two-way interaction bias and two-way interactions are free of other two-way interaction bias.} design, no main effect is aliased with any interaction of fewer than four factors, and no two-way interaction is aliased with any interaction of fewer than three factors. This ensures that all main effects and two-way interactions are estimable without bias from three-way terms, which are assumed negligible under effect sparsity.

The assumption underlying the fractional design is \emph{effect sparsity}: most variation in the response is explained by main effects and two-way interactions, with three-way and higher interactions contributing negligibly. We validate this assumption using LASSO variable selection and nonparametric model comparison.

\subsection{Robustness Checks}

\subsubsection{Inference Corrections}

We compute HC3 robust standard errors (MacKinnon and White, 1985) to account for non-constant error variance across the design space. Comparing OLS standard errors to HC3 robust standard errors, we verify that significance claims hold under heteroscedasticity. The fraction of effects changing significance status under HC3 ranges from 0\% (Experiment~4) to 6.7\% (Experiment~1); per-experiment details appear in Sections~\ref{sec:exp1_robustness} through~\ref{sec:exp4_robustness}.

With $k$ main effects, $\binom{k}{2}$ two-way interactions, and $m$ response variables, each experiment involves many simultaneous hypothesis tests. We apply Holm--Bonferroni sequential correction (Holm, 1979) to control the family-wise error rate at $\alpha = 0.05$. Key findings, including the auction type main effect and the auction type $\times$ exploration interaction, survive this stringent correction across all responses.

For the top~10 effects by absolute $t$-statistic in each response, we compute Rademacher wild bootstrap $p$-values (1{,}000 iterations) to validate inference under minimal distributional assumptions. Bootstrap $p$-values align closely with HC3 asymptotic $p$-values (differences below 0.01), confirming robustness.

We fit quantile regressions at the 10th, 25th, 50th, 75th, and 90th percentiles of each response to assess whether factor effects are uniform across the outcome distribution or concentrated in the tails. An effect that is large at extreme quantiles but small at the median indicates that the factor primarily influences worst-case or best-case configurations rather than the typical outcome. This complements the OLS analysis, which estimates effects at the conditional mean.

\subsubsection{Model Adequacy}

With two replicates per cell, we decompose the residual sum of squares into pure error (within-cell variation) and lack of fit (deviation of cell means from model predictions). The $F$-test $\text{MS}_{\text{LOF}} / \text{MS}_{\text{PE}}$ assesses whether the linear model with two-way interactions adequately fits the data. Per-experiment lack-of-fit results are reported in Sections~\ref{sec:exp1_robustness} through~\ref{sec:exp4_robustness}.

We compute leave-one-out cross-validated $R^2$ using the PRESS statistic:
\begin{align}
  \text{PRESS} = \sum_{i=1}^{n} \left( \frac{e_i}{1 - h_{ii}} \right)^{\!2}, \qquad
  \text{Pred-}R^2 = 1 - \frac{\text{PRESS}}{\text{SS}_{\text{Total}}},
  \label{eq:press}
\end{align}
where $e_i$ is the $i$-th ordinary residual and $h_{ii}$ is the $i$-th diagonal element of the hat matrix. A gap between $R^2$ and Pred-$R^2$ smaller than 0.10 indicates minimal overfitting. Predicted $R^2$ and PRESS gaps vary across experiments and are reported in each experiment's model adequacy table (Tables~\ref{tab:exp1_adequacy}--\ref{tab:exp4_adequacy}).

Gradient-boosted machines (LightGBM, 200 trees, maximum depth~4) are fit using five-fold cross-validation to establish a nonparametric upper bound on achievable $R^2$. If OLS $R^2$ is within 0.05 of LightGBM $R^2$, we conclude that the linear model with two-way interactions captures most of the signal and that higher-order or nonlinear terms contribute negligibly. In all experiments, OLS $R^2$ meets or exceeds LightGBM cross-validated $R^2$, confirming that the parametric model is well suited to the balanced factorial structure (see per-experiment diagnostics in Tables~\ref{tab:exp1_adequacy}--\ref{tab:exp4_adequacy}).

\subsubsection{Variable Selection and Power}

We fit five-fold cross-validated LASSO models with regularisation parameter $\lambda$ chosen to minimise mean squared error. Surviving variables are compared to OLS significance: in all experiments, LASSO retains auction type and number of bidders, corroborating OLS effect selection. Heredity is verified by checking that no interaction survives whose parent main effects were dropped.

We compute minimum detectable effects (MDE) at 80\% power and $\alpha = 0.05$ for balanced $2^k$ designs:
\begin{align}
  \text{MDE}_{\text{main}} = \bigl(t_{\text{crit}} + t_{0.80}\bigr) \times \frac{\hat{\sigma}}{\sqrt{n}},
  \label{eq:mde}
\end{align}
where $t_{\text{crit}}$ is the critical value at $\alpha/2$, $t_{0.80}$ is the 80th percentile of the $t$-distribution, $\hat{\sigma}$ is the estimated residual standard deviation, and $n$ is the total number of observations. MDEs range from 2--5\% of the mean response, indicating that the designs have sufficient power to detect practically meaningful effects.

\subsection{Diagnostic Visualisations}

Four types of diagnostic plots accompany each response variable. Pareto charts rank effects by absolute $t$-statistic in descending order, with effects surpassing the critical threshold $t_{\alpha/2,\,\text{df}}$ shown in red, providing a visual hierarchy of effect importance. Main effects plots display the mean response at the low ($-1$) and high ($+1$) levels of each factor; steeper slopes correspond to larger $|\beta_j|$ values. Interaction plots show the mean response across the four combinations $(x_j, x_l) \in \{(-1,-1), (-1,+1), (+1,-1), (+1,+1)\}$ for the top six interactions by $|t|$-statistic; non-parallel lines indicate that the effect of one factor depends on the level of another. Half-normal probability plots display $|\hat{\beta}_j|$ against expected order statistics from a half-normal distribution, separating active effects (large departures from the reference line) from noise (points following the line). Residual diagnostics include quantile--quantile plots assessing normality and residuals-versus-fitted plots checking for heteroscedasticity and nonlinearity.

\subsection{Reporting}

All results report OLS coefficients with standard errors. Effect sizes are interpreted as practical significance (magnitude relative to mean response) in addition to statistical significance ($p$-value threshold). Each experiment's results section includes a model adequacy table (Tables~\ref{tab:exp1_adequacy}--\ref{tab:exp4_adequacy}) reporting $R^2$, Pred-$R^2$, LightGBM $R^2$, and lack-of-fit $p$-value, and an inference robustness table (Tables~\ref{tab:exp1_inference}--\ref{tab:exp4_inference}) reporting HC3 flips, Holm--Bonferroni survivors, and Benjamini--Hochberg survivors. All effects reported as statistically significant in the results sections survive Benjamini--Hochberg correction.
